{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37235258",
   "metadata": {},
   "source": [
    "# Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab8e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow numpy pandas sklearn matplotlib nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ffac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0cb575",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code assumes a CSV file with columns \"review\" and \"sentiment\"\n",
    "dataset_path = 'path/to/your/dataset.csv'  # Provide the path to your dataset\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Check the first few rows of the dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd460d2",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2db611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "MAX_LEN = 100  # Maximum length of sequences\n",
    "VOCAB_SIZE = 10000  # Size of the vocabulary\n",
    "\n",
    "# Tokenize and pad the sequences\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(data['review'])\n",
    "\n",
    "# Convert the text to sequences\n",
    "sequences = tokenizer.texts_to_sequences(data['review'])\n",
    "\n",
    "# Pad the sequences to the same length\n",
    "padded_sequences = pad_sequences(sequences, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "# Convert sentiments to numerical labels\n",
    "sentiment_to_index = {'positive': 1, 'negative': 0, 'neutral': 2}\n",
    "data['sentiment_index'] = data['sentiment'].map(sentiment_to_index)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, data['sentiment_index'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771c37d5",
   "metadata": {},
   "source": [
    "# Model Preparation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b941806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=VOCAB_SIZE, output_dim=128, input_length=MAX_LEN),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faaec70",
   "metadata": {},
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Generate a classification report\n",
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['negative', 'positive', 'neutral']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb04d33",
   "metadata": {},
   "source": [
    "# Saving and Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('sentiment_analysis_model.h5')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('sentiment_analysis_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3864a8a1",
   "metadata": {},
   "source": [
    "# Performing Sentiment Analysis on New Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad0697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_sentiment_analysis(review, tokenizer, model):\n",
    "    # Tokenize and pad the review\n",
    "    sequence = tokenizer.texts_to_sequences([review])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "\n",
    "    # Predict the sentiment\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    sentiment_index = np.argmax(prediction)\n",
    "    index_to_sentiment = {0: 'negative', 1: 'positive', 2: 'neutral'}\n",
    "\n",
    "    # Return the predicted sentiment\n",
    "    return index_to_sentiment[sentiment_index]\n",
    "\n",
    "# Example usage\n",
    "new_review = \"The product quality is great, but the delivery was late.\"\n",
    "predicted_sentiment = perform_sentiment_analysis(new_review, tokenizer, model)\n",
    "print(f'Predicted Sentiment: {predicted_sentiment}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
